{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "- # 요약\n",
    "    - ## Maximun Likelihood Estimation(MLE)\n",
    "    - ## Train/dev/test set\n",
    "        - test\n",
    "    - ### 3-2-1, 3-3-1 참조\n",
    "    - ## 데이터 전처리\n",
    "        \n",
    "    - ## MNIST\n",
    "        - Epoch, batch size, iteration\n",
    "        \n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최적화\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, optimizer, x_test, y_test):\n",
    "    prediction = model(x_test)\n",
    "    predicted_classes = prediction.max(1)[1]\n",
    "    correct_count = (predicted_classes == y_test).sum().item()\n",
    "    cost = F.cross_entropy(prediction, y_test)\n",
    "\n",
    "    print('Accuracy: {}% Cost: {:.6f}'.format(\n",
    "         correct_count / len(y_test) * 100, cost.item()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리\n",
    "- 3-2-1 참조\n",
    "- 입력 데이터 정규화해 입력 값 범위 제한하고, 아웃라이어 반영 강도 낮춤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 90],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ x'_j = \\frac{x_j - \\mu_j}{\\sigma_j} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 $\\sigma$ 는 standard deviation, $\\mu$ 는 평균값 이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = x_train.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = x_train.std(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_x_train = (x_train - mu) / sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0674, -0.3758, -0.8398],\n",
      "        [ 0.7418,  0.2778,  0.5863],\n",
      "        [ 0.3799,  0.5229,  0.3486],\n",
      "        [ 1.0132,  1.0948,  1.1409],\n",
      "        [-1.0674, -1.5197, -1.2360]])\n"
     ]
    }
   ],
   "source": [
    "print(norm_x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST\n",
    "- 0~9 까지의 손글씨 이미지 가진 데이터셋\n",
    "- 28*28 단일 채널 이미지임\n",
    "- torchvision.dataset 를 통해 접근가능함\n",
    "- Epoch,batch size, iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 7 Learning rate and Evaluation\n",
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# for reproducibility\n",
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:04<00:00, 2.27MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 161kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.45MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 2.90MB/s]\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST data image of shape 28 * 28 = 784\n",
    "linear = torch.nn.Linear(784, 10, bias=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.535150588\n",
      "Epoch: 0002 cost = 0.359577715\n",
      "Epoch: 0003 cost = 0.331264287\n",
      "Epoch: 0004 cost = 0.316404700\n",
      "Epoch: 0005 cost = 0.307106972\n",
      "Epoch: 0006 cost = 0.300456554\n",
      "Epoch: 0007 cost = 0.294933408\n",
      "Epoch: 0008 cost = 0.290956199\n",
      "Epoch: 0009 cost = 0.287074089\n",
      "Epoch: 0010 cost = 0.284515649\n",
      "Epoch: 0011 cost = 0.281914055\n",
      "Epoch: 0012 cost = 0.279526889\n",
      "Epoch: 0013 cost = 0.277636617\n",
      "Epoch: 0014 cost = 0.275874794\n",
      "Epoch: 0015 cost = 0.274422765\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = len(data_loader)\n",
    "\n",
    "    for X, Y in data_loader:\n",
    "        # reshape input image into [batch_size by 784]\n",
    "        # label is not one-hot encoded\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = linear(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8883000016212463\n",
      "Label:  8\n",
      "Prediction:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torchvision/datasets/mnist.py:81: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/opt/conda/lib/python3.11/site-packages/torchvision/datasets/mnist.py:71: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the model using test sets\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = linear(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())\n",
    "\n",
    "    # Get one and predict\n",
    "    r = random.randint(0, len(mnist_test) - 1)\n",
    "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = linear(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
    "\n",
    "    plt.imshow(mnist_test.test_data[r:r + 1].view(28, 28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
