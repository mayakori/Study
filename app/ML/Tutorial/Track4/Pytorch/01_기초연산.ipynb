{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# 요약  \n",
    "## 기본 연산  \n",
    "* 벡터, 행렬, 텐서  \n",
    "### Slicing  \n",
    "* 기본 형태  \n",
    "* 음수  \n",
    "* 빈 경우  \n",
    "\n",
    "### Dimension 함수  \n",
    "* dim(), size(), shape  \n",
    "* ndim, shape  \n",
    "\n",
    "### 행렬 간 연산  \n",
    "#### 덧셈  \n",
    "* 브로드캐스팅  \n",
    "\n",
    "#### 곱셈  \n",
    "* 행렬곱  \n",
    "* 곱  \n",
    "\n",
    "### 통계 함수  \n",
    "* mean, sum, max, argmax  \n",
    "* dim  \n",
    "* 연산 후 차원\n",
    "- ## 연산\n",
    "    - ### View\n",
    "        - -1\n",
    "        - [input_sequence]\n",
    "    - ### Squeeze\n",
    "        - 용도\n",
    "        - Dim\n",
    "    - ### Unsqeeze\n",
    "    - ### Type Casting\n",
    "        - 형식\n",
    "    - ### Concatenate\n",
    "        - 형식\n",
    "        - dim\n",
    "        - 출력행렬 크기\n",
    "    - ### stack\n",
    "        - 형식\n",
    "        - dim\n",
    "        - 출력행렬 크기\n",
    "    - ### Ones and Zeros\n",
    "        - 형식\n",
    "        - _like\n",
    "        - full\n",
    "    - ### In-place Operation\n",
    "        - _\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 내용\n",
    "## 기본 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing\n",
    "- 기본 형태  \n",
    "- 음수  \n",
    "- 빈 경우  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4. 5. 6.]\n",
      "Rank of t:  1\n",
      "Shape of t:  (7,)\n",
      "t[0] t[1] t[-1] =  0.0 1.0 6.0\n",
      "t[2:5] t[4:-1]  =  [2. 3. 4.] [4. 5.]\n",
      "t[:2] t[3:]     =  [0. 1.] [3. 4. 5. 6.]\n"
     ]
    }
   ],
   "source": [
    "## numpy 예시\n",
    "t = np.array([0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0])\n",
    "print(t)\n",
    "# [ 0.  1.  2.  3.  4.  5.  6.]\n",
    "\n",
    "print(\"Rank of t: \", t.ndim)\n",
    "print(\"Shape of t: \", t.shape)\n",
    "# Rank of t:  1\n",
    "# Shape of t:  (7,)\n",
    "\n",
    "print(\"t[0] t[1] t[-1] = \", t[0], t[1], t[-1])  # Element\n",
    "print(\"t[2:5] t[4:-1]  = \", t[2:5], t[4:-1])  # Slicing\n",
    "print(\"t[:2] t[3:]     = \", t[:2], t[3:])  # Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3., 4., 5., 6.])\n",
      "1\n",
      "torch.Size([7])\n",
      "torch.Size([7])\n",
      "tensor(0.) tensor(1.) tensor(6.)\n",
      "tensor([2., 3., 4.]) tensor([4., 5.])\n",
      "tensor([0., 1.]) tensor([3., 4., 5., 6.])\n"
     ]
    }
   ],
   "source": [
    "## pytorch 예시\n",
    "## 곱셈,행렬곱 체크\n",
    "t = torch.FloatTensor([0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0])\n",
    "print(t)\n",
    "# tensor([0., 1., 2., 3., 4., 5., 6.])\n",
    "\n",
    "print(t.dim())  # rank\n",
    "# 1\n",
    "\n",
    "print(t.shape)  # shape\n",
    "# torch.Size([7])\n",
    "\n",
    "print(t.size())  # shape\n",
    "# torch.Size([7])\n",
    "\n",
    "print(t[0], t[1], t[-1])  # Element\n",
    "# tensor(0.) tensor(1.) tensor(6.)\n",
    "\n",
    "print(t[2:5], t[4:-1])  # Slicing\n",
    "# tensor([2., 3., 4.]) tensor([4., 5.])\n",
    "\n",
    "print(t[:2], t[3:])  # Slicing\n",
    "# tensor([0., 1.]) tensor([3., 4., 5., 6.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimension 함수\n",
    "- dim(), size(), shape  \n",
    "- ndim, shape  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "2\n",
      "torch.Size([4, 3])\n",
      "tensor([4., 5., 6.])\n",
      "torch.Size([4])\n",
      "tensor([[ 1.,  2.],\n",
      "        [ 4.,  5.],\n",
      "        [ 7.,  8.],\n",
      "        [10., 11.]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1., 2., 3.],\n",
    "                       [4., 5., 6.],\n",
    "                       [7., 8., 9.],\n",
    "                       [10., 11., 12.]])\n",
    "print(t)\n",
    "\n",
    "# 출력 결과는 다음과 같을 것입니다:\n",
    "# tensor([[ 1.,  2.,  3.],\n",
    "#         [ 4.,  5.,  6.],\n",
    "#         [ 7.,  8.,  9.],\n",
    "#         [10., 11., 12.]])\n",
    "\n",
    "print(t.dim())  # rank - 차원 수\n",
    "print(t.size())  # shape - 텐서의 형태\n",
    "\n",
    "# 이미지에서 보이는 것으로 t[1] 출력하는 부분이 있는데, 이는 두 번째 행을 의미합니다.\n",
    "print(t[1])\n",
    "\n",
    "print(t[:, 1].size())  # 모든 행의 두 번째 열의 크기\n",
    "print(t[:, :-1])  # 모든 행과 마지막 열을 제외한 모든 열"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 행렬 간 연산\n",
    "#### 덧셈\n",
    "- 브로드캐스팅  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 5.]])\n",
      "tensor([[4., 5.]])\n",
      "tensor([[4., 5.],\n",
      "        [5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "## 브로드캐스팅 예제\n",
    "## 커지는 모양 체크\n",
    "\n",
    "# Same shape\n",
    "m1 = torch.FloatTensor([[3, 3]])\n",
    "m2 = torch.FloatTensor([[2, 2]])\n",
    "print(m1 + m2)\n",
    "# tensor([[5., 5.]])\n",
    "\n",
    "# Vector + scalar\n",
    "m1 = torch.FloatTensor([[1, 2]])\n",
    "m2 = torch.FloatTensor([[3]])  # 3 -> [[3, 3]]\n",
    "print(m1 + m2)\n",
    "# tensor([[4., 5.]])\n",
    "\n",
    "# 2 x 1 Vector + 1 x 2 Vector\n",
    "m1 = torch.FloatTensor([[1, 2]])  # 1x2 벡터\n",
    "m2 = torch.FloatTensor([[3], [4]])  # 2x1 벡터\n",
    "print(m1 + m2)\n",
    "# tensor([[4., 5.],\n",
    "#         [5., 6.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 곱셈\n",
    "- 행렬곱  \n",
    "- 곱  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------\n",
      "Mat vs Matmul\n",
      "---------------\n",
      "Shape of Matrix 1:  torch.Size([2, 2])\n",
      "Shape of Matrix 2:  torch.Size([2, 1])\n",
      "tensor([[ 7.],\n",
      "        [17.]])\n",
      "Shape of Matrix 1:  torch.Size([2, 2])\n",
      "Shape of Matrix 2:  torch.Size([2, 1])\n",
      "tensor([[3., 6.],\n",
      "        [6., 8.]])\n",
      "tensor([[3., 6.],\n",
      "        [6., 8.]])\n"
     ]
    }
   ],
   "source": [
    "## 곱, 행렬곱\n",
    "print()\n",
    "print(\"---------------\")\n",
    "print(\"Mat vs Matmul\")\n",
    "print(\"---------------\")\n",
    "\n",
    "# 첫 번째 예제: matmul 연산\n",
    "m1 = torch.FloatTensor([[1, 2], [3, 4]])  # 2×2 행렬\n",
    "m2 = torch.FloatTensor([[3], [2]])  # 2×1 행렬(열 벡터)\n",
    "print(\"Shape of Matrix 1: \", m1.shape)  # 2 x 2\n",
    "print(\"Shape of Matrix 2: \", m2.shape)  # 2 x 1\n",
    "print(m1.matmul(m2))  # 행렬 곱셈 결과 (2×1 행렬)\n",
    "\n",
    "# 두 번째 예제: 원소별 곱셈(element-wise multiplication)\n",
    "m1 = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "m2 = torch.FloatTensor([[3], [2]])\n",
    "print(\"Shape of Matrix 1: \", m1.shape)  # 2 x 2\n",
    "print(\"Shape of Matrix 2: \", m2.shape)  # 2 x 1\n",
    "print(m1 * m2)  # 브로드캐스팅된 원소별 곱셈\n",
    "print(m1.mul(m2))  # mul() 메소드도 동일한 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 통계 함수\n",
    "- mean, sum, max, argmax  \n",
    "- dim  \n",
    "- 연산 후 차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5000)\n",
      "mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor(2.5000)\n",
      "tensor([2., 3.])\n",
      "tensor([1.5000, 3.5000])\n",
      "tensor([1.5000, 3.5000])\n"
     ]
    }
   ],
   "source": [
    "## mean, sum, max, argmax\n",
    "## 행렬 크기 직관적으로 볼 떄는 바깥쪽부터 원소수를 세면서 대괄호를 하나씩 제거해나가면 됨\n",
    "## n 차원 행렬에 대해 차원 지정해 연산시 지정한 차원이 사라진 n-1 차원의 행렬을 출력으로 내보낸다\n",
    "## keepdim=True 로 설정 시 지정된 차원이 사리지지 않고 크기가 1로 변한다.\n",
    "## 여러 차원을 선택히 모든 지정차원이 사라진다\n",
    "## dim 에 해당되지 않으면 다른 인덱스는 고정시키고, dim 에 해당되는 인덱스만 값을 변경시키며 연산한다.\n",
    "\n",
    "\n",
    "# 1. 기본적인 평균 계산 - 1차원 텐서\n",
    "t = torch.FloatTensor([1, 2])\n",
    "print(t.mean())  # tensor(1.5000)\n",
    "\n",
    "# 2. 정수형 텐서(LongTensor)에서는 mean() 사용 불가\n",
    "# Can't use mean() on integers\n",
    "t = torch.LongTensor([1, 2])\n",
    "try:\n",
    "    print(t.mean())\n",
    "except Exception as exc:\n",
    "    print(exc)  # Can only calculate the mean of floating types. Got Long instead.\n",
    "\n",
    "# 3. 고차원 텐서 생성\n",
    "t = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "print(t)\n",
    "# tensor([[1., 2.],\n",
    "#         [3., 4.]])\n",
    "\n",
    "# 4. 다양한 차원에서의 평균 계산\n",
    "print(t.mean())  # 모든 원소의 평균: tensor(2.5000)\n",
    "print(t.mean(dim=0))  # 열 방향 평균(각 열에 대한 평균): tensor([2., 3.])\n",
    "print(t.mean(dim=1))  # 행 방향 평균(각 행에 대한 평균): tensor([1.5000, 3.5000])\n",
    "print(t.mean(dim=-1))  # 마지막 차원 방향 평균(dim=1과 동일): tensor([1.5000, 3.5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "텐서 shape: torch.Size([2, 2])\n",
      "tensor(4.)\n",
      "torch.return_types.max(\n",
      "values=tensor([3., 4.]),\n",
      "indices=tensor([1, 1]))\n",
      "Max:  tensor([3., 4.])\n",
      "Argmax:  tensor([1, 1])\n",
      "torch.return_types.max(\n",
      "values=tensor([2., 4.]),\n",
      "indices=tensor([1, 1]))\n",
      "torch.return_types.max(\n",
      "values=tensor([2., 4.]),\n",
      "indices=tensor([1, 1]))\n"
     ]
    }
   ],
   "source": [
    "## argmax\n",
    "## 요소 중 최대값을 가진 인덱스 반환\n",
    "\n",
    "# 3차원 텐서 생성  \n",
    "t = torch.FloatTensor([[1, 2], [3, 4]])  \n",
    "print(t)  \n",
    "print(\"텐서 shape:\", t.shape)  # [ 2, 2]  \n",
    "\n",
    "# 차원 지정 없이 max 호출 - 모든 요소 중 최댓값 반환  \n",
    "print(t.max())  # Returns one value: max  \n",
    "\n",
    "# dim=0 지정하여 max 호출 - 첫 번째 차원을 따라 최댓값과 인덱스 반환  \n",
    "print(t.max(dim=0))  # Returns two values: max and argmax  \n",
    "print(\"Max: \", t.max(dim=0)[0])  \n",
    "print(\"Argmax: \", t.max(dim=0)[1])  \n",
    "\n",
    "# dim=1 지정하여 max 호출 - 두 번째 차원을 따라 최댓값 계산  \n",
    "print(t.max(dim=1))  \n",
    "\n",
    "# dim=-1 지정하여 max 호출 - 마지막 차원을 따라 최댓값 계산  \n",
    "print(t.max(dim=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape\n",
    "- View\n",
    "    - -1\n",
    "        - 알아서 자동으로 크기를 계산하는 차원을 말함\n",
    "        - 입력된 다른 차원 모양을 계산하고 남는 크기를 알아서 맞추는 방법이므로 차원 하나만 -1이 될수있음\n",
    "    - [input_sequence]\n",
    "        - 행렬의 모든 데이터를 일렬로 펼친 후, 입력된 모양에 맞게 재배치함\n",
    "        - 총 원소의 수는 반드시 같아야함\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# 3차원 NumPy 배열 생성 (2x2x3 형태)  \n",
    "t = np.array([[[0, 1, 2],  \n",
    "               [3, 4, 5]],  \n",
    "              \n",
    "              [[6, 7, 8],  \n",
    "               [9, 10, 11]]])  \n",
    "\n",
    "# NumPy 배열을 PyTorch 텐서로 변환  \n",
    "ft = torch.FloatTensor(t)  \n",
    "\n",
    "# 텐서의 형태(shape) 출력  \n",
    "print(ft.shape)  # 결과: torch.Size([2, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.],\n",
      "        [ 3.,  4.,  5.],\n",
      "        [ 6.,  7.,  8.],\n",
      "        [ 9., 10., 11.]])\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "# ft.view([-1, 3])은 텐서를 재구성합니다:  \n",
    "# - 마지막 차원은 3  \n",
    "# - 첫 번째 차원(-1)은 자동으로 계산됨  \n",
    "print(ft.view([-1, 3]))  \n",
    "print(ft.view([-1, 3]).shape)  # 결과: torch.Size([4, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.]],\n",
      "\n",
      "        [[ 3.,  4.,  5.]],\n",
      "\n",
      "        [[ 6.,  7.,  8.]],\n",
      "\n",
      "        [[ 9., 10., 11.]]])\n",
      "torch.Size([4, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "# 마지막으로, 3차원 텐서로 재구성:  \n",
    "# - 마지막 차원은 3  \n",
    "# - 중간 차원은 1  \n",
    "# - 첫 번째 차원(-1)은 자동으로 계산됨  \n",
    "print(ft.view([-1, 1, 3]))  \n",
    "print(ft.view([-1, 1, 3]).shape)  # 결과: torch.Size([4, 1, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squeeze\n",
    "- 크기가 1인 단일 차원 제거\n",
    "- dim\n",
    "    - 지정된 차원의 크기가 1인 경우 제거\n",
    "    - 값이랑 무관\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 텐서 형태: torch.Size([1, 2, 1, 3, 1])\n",
      "\n",
      "모든 단일 차원 제거 - squeeze(): torch.Size([2, 3])\n",
      "\n",
      "특정 차원만 squeeze:\n",
      "squeeze(dim=0): torch.Size([2, 1, 3, 1])\n",
      "squeeze(dim=2): torch.Size([1, 2, 3, 1])\n",
      "squeeze(dim=4): torch.Size([1, 2, 1, 3])\n",
      "\n",
      "크기가 1이 아닌 차원 squeeze 시도:\n",
      "squeeze(dim=1): torch.Size([1, 2, 1, 3, 1])\n",
      "squeeze(dim=3): torch.Size([1, 2, 1, 3, 1])\n",
      "\n",
      "음수 인덱스 사용:\n",
      "squeeze(dim=-1): torch.Size([1, 2, 1, 3])\n",
      "squeeze(dim=-3): torch.Size([1, 2, 3, 1])\n",
      "squeeze(dim=-5): torch.Size([2, 1, 3, 1])\n",
      "\n",
      "여러 차원 순차적으로 squeeze:\n",
      "순차 squeeze 결과: torch.Size([2, 3])\n",
      "\n",
      "다양한 dim 파라미터 문법:\n",
      "squeeze(0): torch.Size([2, 1, 3, 1])\n",
      "squeeze(dim=0): torch.Size([2, 1, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch  \n",
    "\n",
    "# squeeze()의 dim 파라미터 다양한 사용 예제  \n",
    "def demonstrate_squeeze_with_dim():  \n",
    "    # 테스트용 다차원 텐서 생성 (형태: [1,2,1,3,1])  \n",
    "    tensor = torch.randn(1, 2, 1, 3, 1)  \n",
    "    print(f\"원본 텐서 형태: {tensor.shape}\")  \n",
    "    \n",
    "    # 1. dim 지정 없이 모든 단일 차원 제거  \n",
    "    print(f\"\\n모든 단일 차원 제거 - squeeze(): {tensor.squeeze().shape}\")  # [2,3]  \n",
    "    \n",
    "    # 2. 양수 인덱스로 특정 차원 squeeze  \n",
    "    print(f\"\\n특정 차원만 squeeze:\")  \n",
    "    print(f\"squeeze(dim=0): {tensor.squeeze(dim=0).shape}\")    # [2,1,3,1] - 첫 번째 차원(인덱스 0) 제거  \n",
    "    print(f\"squeeze(dim=2): {tensor.squeeze(dim=2).shape}\")    # [1,2,3,1] - 세 번째 차원(인덱스 2) 제거  \n",
    "    print(f\"squeeze(dim=4): {tensor.squeeze(dim=4).shape}\")    # [1,2,1,3] - 다섯 번째 차원(인덱스 4) 제거  \n",
    "    \n",
    "    # 3. 크기가 1이 아닌 차원에 squeeze 시도 (변화 없음)  \n",
    "    print(f\"\\n크기가 1이 아닌 차원 squeeze 시도:\")  \n",
    "    print(f\"squeeze(dim=1): {tensor.squeeze(dim=1).shape}\")    # [1,2,1,3,1] - 변화 없음 (크기가 1이 아님)  \n",
    "    print(f\"squeeze(dim=3): {tensor.squeeze(dim=3).shape}\")    # [1,2,1,3,1] - 변화 없음 (크기가 1이 아님)  \n",
    "    \n",
    "    # 4. 음수 인덱스로 차원 지정 (-1: 마지막 차원)  \n",
    "    print(f\"\\n음수 인덱스 사용:\")  \n",
    "    print(f\"squeeze(dim=-1): {tensor.squeeze(dim=-1).shape}\")  # [1,2,1,3] - 마지막 차원 제거  \n",
    "    print(f\"squeeze(dim=-3): {tensor.squeeze(dim=-3).shape}\")  # [1,2,3,1] - 뒤에서 세 번째 차원 제거  \n",
    "    print(f\"squeeze(dim=-5): {tensor.squeeze(dim=-5).shape}\")  # [2,1,3,1] - 뒤에서 다섯 번째(첫 번째) 차원 제거  \n",
    "    \n",
    "    # 5. 여러 번 squeeze 연속 적용  \n",
    "    print(f\"\\n여러 차원 순차적으로 squeeze:\")  \n",
    "    result = tensor.squeeze(dim=0).squeeze(dim=1).squeeze(dim=-1)  \n",
    "    print(f\"순차 squeeze 결과: {result.shape}\")  # [2,3]  \n",
    "    \n",
    "    # 6. dim 파라미터의 다양한 문법  \n",
    "    print(f\"\\n다양한 dim 파라미터 문법:\")  \n",
    "    print(f\"squeeze(0): {tensor.squeeze(0).shape}\")          # 위치 인자  \n",
    "    print(f\"squeeze(dim=0): {tensor.squeeze(dim=0).shape}\")  # 키워드 인자  \n",
    "\n",
    "# 함수 실행  \n",
    "demonstrate_squeeze_with_dim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsqueeze\n",
    "    - 지정된 dim 차원에 크기가 1인 새 차원을 삽입함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 텐서 형태: torch.Size([2, 3])\n",
      "\n",
      "다양한 위치에 차원 추가:\n",
      "unsqueeze(dim=0): torch.Size([1, 2, 3])\n",
      "unsqueeze(dim=1): torch.Size([2, 1, 3])\n",
      "unsqueeze(dim=2): torch.Size([2, 3, 1])\n",
      "\n",
      "음수 인덱스 사용:\n",
      "unsqueeze(dim=-1): torch.Size([2, 3, 1])\n",
      "unsqueeze(dim=-2): torch.Size([2, 1, 3])\n",
      "unsqueeze(dim=-3): torch.Size([1, 2, 3])\n",
      "\n",
      "여러 차원 순차적으로 unsqueeze:\n",
      "unsqueeze(0) 후 unsqueeze(-1) 결과: torch.Size([1, 2, 3, 1])\n",
      "\n",
      "1차원 벡터 형태: torch.Size([4])\n",
      "행 벡터로 변환 - unsqueeze(0): torch.Size([1, 4])\n",
      "열 벡터로 변환 - unsqueeze(1): torch.Size([4, 1])\n",
      "\n",
      "인플레이스 연산 전 형태: torch.Size([2, 3])\n",
      "unsqueeze_(0) 후 원본 형태: torch.Size([1, 2, 3])\n",
      "\n",
      "단일 이미지 형태: torch.Size([3, 224, 224])\n",
      "배치 차원 추가 후: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "다양한 dim 파라미터 문법:\n",
      "unsqueeze(0): torch.Size([1, 2, 3])\n",
      "unsqueeze(dim=0): torch.Size([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch  \n",
    "\n",
    "# unsqueeze()의 다양한 사용 예제  \n",
    "def demonstrate_unsqueeze_with_dim():  \n",
    "    # 테스트용 텐서 생성 (형태: [2,3])  \n",
    "    tensor = torch.randn(2, 3)  \n",
    "    print(f\"원본 텐서 형태: {tensor.shape}\")  \n",
    "    \n",
    "    # 1. 다양한 위치에 차원 추가  \n",
    "    print(f\"\\n다양한 위치에 차원 추가:\")  \n",
    "    print(f\"unsqueeze(dim=0): {tensor.unsqueeze(dim=0).shape}\")  # [1,2,3] - 첫 번째 위치에 차원 추가  \n",
    "    print(f\"unsqueeze(dim=1): {tensor.unsqueeze(dim=1).shape}\")  # [2,1,3] - 두 번째 위치에 차원 추가  \n",
    "    print(f\"unsqueeze(dim=2): {tensor.unsqueeze(dim=2).shape}\")  # [2,3,1] - 세 번째 위치에 차원 추가  \n",
    "    \n",
    "    # 2. 음수 인덱스로 차원 지정 (-1: 마지막 위치 이후)  \n",
    "    print(f\"\\n음수 인덱스 사용:\")  \n",
    "    print(f\"unsqueeze(dim=-1): {tensor.unsqueeze(dim=-1).shape}\")  # [2,3,1] - 마지막 위치에 차원 추가  \n",
    "    print(f\"unsqueeze(dim=-2): {tensor.unsqueeze(dim=-2).shape}\")  # [2,1,3] - 마지막에서 두 번째 위치에 차원 추가  \n",
    "    print(f\"unsqueeze(dim=-3): {tensor.unsqueeze(dim=-3).shape}\")  # [1,2,3] - 마지막에서 세 번째(첫 번째) 위치에 차원 추가  \n",
    "    \n",
    "    # 3. 여러 번 unsqueeze 연속 적용  \n",
    "    print(f\"\\n여러 차원 순차적으로 unsqueeze:\")  \n",
    "    result = tensor.unsqueeze(dim=0).unsqueeze(dim=-1)  \n",
    "    print(f\"unsqueeze(0) 후 unsqueeze(-1) 결과: {result.shape}\")  # [1,2,3,1]  \n",
    "    \n",
    "    # 4. 1차원 텐서에 unsqueeze 적용  \n",
    "    vector = torch.tensor([1, 2, 3, 4])  # 형태: [4]  \n",
    "    print(f\"\\n1차원 벡터 형태: {vector.shape}\")  \n",
    "    print(f\"행 벡터로 변환 - unsqueeze(0): {vector.unsqueeze(0).shape}\")  # [1,4] (행 벡터)  \n",
    "    print(f\"열 벡터로 변환 - unsqueeze(1): {vector.unsqueeze(1).shape}\")  # [4,1] (열 벡터)  \n",
    "    \n",
    "    # 5. 인플레이스 연산 - 원본 변경  \n",
    "    tensor_copy = tensor.clone()  \n",
    "    print(f\"\\n인플레이스 연산 전 형태: {tensor_copy.shape}\")  \n",
    "    tensor_copy.unsqueeze_(dim=0)  # 인플레이스 연산 (원본 변경)  \n",
    "    print(f\"unsqueeze_(0) 후 원본 형태: {tensor_copy.shape}\")  \n",
    "    \n",
    "    # 6. 실제 사용 사례: 배치 차원 추가  \n",
    "    sample = torch.randn(3, 224, 224)  # 단일 이미지 [채널, 높이, 너비]  \n",
    "    print(f\"\\n단일 이미지 형태: {sample.shape}\")  \n",
    "    batch = sample.unsqueeze(0)  # 배치 차원 추가 [배치, 채널, 높이, 너비]  \n",
    "    print(f\"배치 차원 추가 후: {batch.shape}\")  \n",
    "    \n",
    "    # 7. dim 파라미터의 다양한 문법  \n",
    "    print(f\"\\n다양한 dim 파라미터 문법:\")  \n",
    "    print(f\"unsqueeze(0): {tensor.unsqueeze(0).shape}\")          # 위치 인자  \n",
    "    print(f\"unsqueeze(dim=0): {tensor.unsqueeze(dim=0).shape}\")  # 키워드 인자  \n",
    "\n",
    "# 함수 실행  \n",
    "demonstrate_unsqueeze_with_dim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type Casting\n",
    "- 이름.자료형() 형태로 텐서 형변환함\n",
    "- 어떤 자료형 있는지 잘 알아둘것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "기본 텐서 생성\n",
      "==================================================\n",
      "기본 텐서:      tensor([1.5000, 2.0000, 3.7000])\n",
      "데이터 타입:    torch.float32\n",
      "\n",
      "==================================================\n",
      "to() 메서드를 사용한 타입 변환\n",
      "==================================================\n",
      "float64로 변환: tensor([1.5000, 2.0000, 3.7000], dtype=torch.float64)\n",
      "타입:           torch.float64\n",
      "\n",
      "int32로 변환:   tensor([1, 2, 3], dtype=torch.int32)\n",
      "타입:           torch.int32\n",
      "\n",
      "bool로 변환:    tensor([True, True, True])\n",
      "타입:           torch.bool\n",
      "\n",
      "==================================================\n",
      "타입별 특화 메서드 사용\n",
      "==================================================\n",
      "float():        tensor([1.5000, 2.0000, 3.7000])\n",
      "타입:           torch.float32\n",
      "\n",
      "double():       tensor([1.5000, 2.0000, 3.7000], dtype=torch.float64)\n",
      "타입:           torch.float64\n",
      "\n",
      "half():         tensor([1.5000, 2.0000, 3.6992], dtype=torch.float16)\n",
      "타입:           torch.float16\n",
      "\n",
      "long():         tensor([1, 2, 3])\n",
      "타입:           torch.int64\n",
      "\n",
      "int():          tensor([1, 2, 3], dtype=torch.int32)\n",
      "타입:           torch.int32\n",
      "\n",
      "==================================================\n",
      "텐서 생성 시 타입 지정\n",
      "==================================================\n",
      "float32로 생성: tensor([1., 2., 3.])\n",
      "타입:           torch.float32\n",
      "\n",
      "int64로 생성:   tensor([1, 2, 3])\n",
      "타입:           torch.int64\n",
      "\n",
      "bool로 생성:    tensor([ True, False,  True])\n",
      "타입:           torch.bool\n",
      "\n",
      "==================================================\n",
      "타입 변환 시 데이터 변화 확인\n",
      "==================================================\n",
      "원본:                 tensor([1.7000, 2.3000, 3.9000])\n",
      "원본 타입:            torch.float32\n",
      "\n",
      "int()로 변환:         tensor([1, 2, 3], dtype=torch.int32)\n",
      "변환 후 타입:         torch.int32\n",
      "\n",
      "bool()로 변환:        tensor([True, True, True])\n",
      "변환 후 타입:         torch.bool\n",
      "\n",
      "float16으로 변환:     tensor([1.7002, 2.3008, 3.9004], dtype=torch.float16)\n",
      "변환 후 타입:         torch.float16\n",
      "\n",
      "==================================================\n",
      "연산에서의 타입 변환\n",
      "==================================================\n",
      "a:               tensor([1, 2, 3], dtype=torch.int32)\n",
      "a 타입:          torch.int32\n",
      "\n",
      "b:               tensor([0.1000, 0.2000, 0.3000])\n",
      "b 타입:          torch.float32\n",
      "\n",
      "a + b:           tensor([1.1000, 2.2000, 3.3000])\n",
      "결과 타입:       torch.float32\n",
      "\n",
      "==================================================\n",
      "메모리 효율성\n",
      "==================================================\n",
      "float32 데이터 타입:  torch.float32\n",
      "float32 메모리:       100 바이트\n",
      "\n",
      "float16 데이터 타입:  torch.float16\n",
      "float16 메모리:       50 바이트\n",
      "\n",
      "uint8 데이터 타입:    torch.uint8\n",
      "uint8 메모리:         25 바이트\n",
      "\n",
      "==================================================\n",
      "불리언 마스킹\n",
      "==================================================\n",
      "마스크:              tensor([ True, False,  True, False,  True])\n",
      "마스크 타입:         torch.bool\n",
      "\n",
      "값:                  tensor([0., 1., 2., 3., 4.])\n",
      "값 타입:             torch.float32\n",
      "\n",
      "마스킹 결과:         tensor([0., 2., 4.])\n",
      "\n",
      "마스크를 float로:    tensor([1., 0., 1., 0., 1.])\n",
      "변환 후 타입:        torch.float32\n",
      "\n",
      "마스크로 계산:       tensor([0., 0., 2., 0., 4.])\n",
      "계산 결과 타입:      torch.float32\n"
     ]
    }
   ],
   "source": [
    "import torch  \n",
    "\n",
    "def demonstrate_type_casting():  \n",
    "    \"\"\"PyTorch 텐서 타입 캐스팅 종합 예제\"\"\"  \n",
    "    \n",
    "    print(\"=\" * 50)  \n",
    "    print(\"기본 텐서 생성\")  \n",
    "    print(\"=\" * 50)  \n",
    "    x = torch.tensor([1.5, 2.0, 3.7])  \n",
    "    print(f\"기본 텐서:      {x}\")  \n",
    "    print(f\"데이터 타입:    {x.dtype}\")  # 기본은 float32  \n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)  \n",
    "    print(\"to() 메서드를 사용한 타입 변환\")  \n",
    "    print(\"=\" * 50)  \n",
    "    x_float64 = x.to(torch.float64)  # 또는 x.to(dtype=torch.float64)  \n",
    "    x_int32 = x.to(torch.int32)  \n",
    "    x_bool = x.to(torch.bool)  \n",
    "    \n",
    "    print(f\"float64로 변환: {x_float64}\")  \n",
    "    print(f\"타입:           {x_float64.dtype}\")  \n",
    "    print(\"\")  \n",
    "    print(f\"int32로 변환:   {x_int32}\")  \n",
    "    print(f\"타입:           {x_int32.dtype}\")  \n",
    "    print(\"\")  \n",
    "    print(f\"bool로 변환:    {x_bool}\")  \n",
    "    print(f\"타입:           {x_bool.dtype}\")  \n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)  \n",
    "    print(\"타입별 특화 메서드 사용\")  \n",
    "    print(\"=\" * 50)  \n",
    "    x_float = x.float()    # float32로 변환  \n",
    "    x_double = x.double()  # float64로 변환  \n",
    "    x_half = x.half()      # float16으로 변환  \n",
    "    x_long = x.long()      # int64로 변환  \n",
    "    x_int = x.int()        # int32로 변환  \n",
    "    \n",
    "    print(f\"float():        {x_float}\")  \n",
    "    print(f\"타입:           {x_float.dtype}\")  \n",
    "    print(\"\")  \n",
    "    print(f\"double():       {x_double}\")  \n",
    "    print(f\"타입:           {x_double.dtype}\")  \n",
    "    print(\"\")  \n",
    "    print(f\"half():         {x_half}\")  \n",
    "    print(f\"타입:           {x_half.dtype}\")  \n",
    "    print(\"\")  \n",
    "    print(f\"long():         {x_long}\")  \n",
    "    print(f\"타입:           {x_long.dtype}\")  \n",
    "    print(\"\")  \n",
    "    print(f\"int():          {x_int}\")  \n",
    "    print(f\"타입:           {x_int.dtype}\")  \n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)  \n",
    "    print(\"텐서 생성 시 타입 지정\")  \n",
    "    print(\"=\" * 50)  \n",
    "    y_float32 = torch.tensor([1, 2, 3], dtype=torch.float32)  \n",
    "    y_int64 = torch.tensor([1, 2, 3], dtype=torch.int64)  \n",
    "    y_bool = torch.tensor([1, 0, 1], dtype=torch.bool)  \n",
    "    \n",
    "    print(f\"float32로 생성: {y_float32}\")  \n",
    "    print(f\"타입:           {y_float32.dtype}\")  \n",
    "    print(\"\")  \n",
    "    print(f\"int64로 생성:   {y_int64}\")  \n",
    "    print(f\"타입:           {y_int64.dtype}\")  \n",
    "    print(\"\")  \n",
    "    print(f\"bool로 생성:    {y_bool}\")  \n",
    "    print(f\"타입:           {y_bool.dtype}\")  \n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)  \n",
    "    print(\"타입 변환 시 데이터 변화 확인\")  \n",
    "    print(\"=\" * 50)  \n",
    "    z = torch.tensor([1.7, 2.3, 3.9])  \n",
    "    print(f\"원본:                 {z}\")  \n",
    "    print(f\"원본 타입:            {z.dtype}\")  \n",
    "    print(\"\")  \n",
    "    print(f\"int()로 변환:         {z.int()}\")         # 소수점 버림(절삭)  \n",
    "    print(f\"변환 후 타입:         {z.int().dtype}\")  \n",
    "    print(\"\")  \n",
    "    print(f\"bool()로 변환:        {z.bool()}\")        # 0 외 값은 모두 True  \n",
    "    print(f\"변환 후 타입:         {z.bool().dtype}\")  \n",
    "    print(\"\")  \n",
    "    print(f\"float16으로 변환:     {z.half()}\")        # 정밀도 감소 가능성  \n",
    "    print(f\"변환 후 타입:         {z.half().dtype}\")  \n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)  \n",
    "    print(\"연산에서의 타입 변환\")  \n",
    "    print(\"=\" * 50)  \n",
    "    a = torch.tensor([1, 2, 3], dtype=torch.int)  \n",
    "    b = torch.tensor([0.1, 0.2, 0.3], dtype=torch.float)  \n",
    "    result = a + b  \n",
    "    \n",
    "    print(f\"a:               {a}\")  \n",
    "    print(f\"a 타입:          {a.dtype}\")  \n",
    "    print(\"\")  \n",
    "    print(f\"b:               {b}\")  \n",
    "    print(f\"b 타입:          {b.dtype}\")  \n",
    "    print(\"\")  \n",
    "    print(f\"a + b:           {result}\")  # 결과는 float (승격)  \n",
    "    print(f\"결과 타입:       {result.dtype}\")  \n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)  \n",
    "    print(\"메모리 효율성\")  \n",
    "    print(\"=\" * 50)  \n",
    "    full_tensor = torch.ones(5, 5, dtype=torch.float32)  \n",
    "    half_tensor = full_tensor.half()  \n",
    "    byte_tensor = torch.ones(5, 5, dtype=torch.uint8)  \n",
    "    \n",
    "    float32_memory = full_tensor.element_size() * full_tensor.numel()  \n",
    "    float16_memory = half_tensor.element_size() * half_tensor.numel()  \n",
    "    uint8_memory = byte_tensor.element_size() * byte_tensor.numel()  \n",
    "    \n",
    "    print(f\"float32 데이터 타입:  {full_tensor.dtype}\")  \n",
    "    print(f\"float32 메모리:       {float32_memory} 바이트\")  \n",
    "    print(\"\")  \n",
    "    print(f\"float16 데이터 타입:  {half_tensor.dtype}\")  \n",
    "    print(f\"float16 메모리:       {float16_memory} 바이트\")  \n",
    "    print(\"\")  \n",
    "    print(f\"uint8 데이터 타입:    {byte_tensor.dtype}\")  \n",
    "    print(f\"uint8 메모리:         {uint8_memory} 바이트\")  \n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)  \n",
    "    print(\"불리언 마스킹\")  \n",
    "    print(\"=\" * 50)  \n",
    "    mask = torch.tensor([True, False, True, False, True])  \n",
    "    values = torch.arange(5, dtype=torch.float)  \n",
    "    \n",
    "    print(f\"마스크:              {mask}\")  \n",
    "    print(f\"마스크 타입:         {mask.dtype}\")  \n",
    "    print(\"\")  \n",
    "    print(f\"값:                  {values}\")  \n",
    "    print(f\"값 타입:             {values.dtype}\")  \n",
    "    print(\"\")  \n",
    "    print(f\"마스킹 결과:         {values[mask]}\")  \n",
    "    print(\"\")  \n",
    "    print(f\"마스크를 float로:    {mask.float()}\")  # True=1.0, False=0.0  \n",
    "    print(f\"변환 후 타입:        {mask.float().dtype}\")  \n",
    "    print(\"\")  \n",
    "    print(f\"마스크로 계산:       {values * mask.float()}\")  \n",
    "    print(f\"계산 결과 타입:      {(values * mask.float()).dtype}\")  \n",
    "\n",
    "# 함수 실행  \n",
    "demonstrate_type_casting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate\n",
    "- torch.cat([x.y],dim=0)\n",
    "- 두 행렬을 지정된 차원에 이어붙인다\n",
    "    - 출력행렬의 크기는 지정된 차원만 커진다\n",
    "    - [2,3], [2,3] 크기의 행렬을 dim=1 로 이어붙이면\n",
    "    - [2,6] 크기의 행렬이 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.],\n",
      "        [7., 8.]])\n",
      "tensor([[1., 2., 5., 6.],\n",
      "        [3., 4., 7., 8.]])\n"
     ]
    }
   ],
   "source": [
    "import torch  \n",
    "\n",
    "# 2차원 텐서 생성  \n",
    "x = torch.FloatTensor([[1, 2], [3, 4]])  \n",
    "y = torch.FloatTensor([[5, 6], [7, 8]])  \n",
    "\n",
    "# dim=0으로 연결 (행 방향)  \n",
    "result_dim0 = torch.cat([x, y], dim=0)  \n",
    "print(result_dim0)  \n",
    "# 출력:  \n",
    "# tensor([[1., 2.],  \n",
    "#         [3., 4.],  \n",
    "#         [5., 6.],  \n",
    "#         [7., 8.]])  \n",
    "\n",
    "# dim=1로 연결 (열 방향)  \n",
    "result_dim1 = torch.cat([x, y], dim=1)  \n",
    "print(result_dim1)  \n",
    "# 출력:  \n",
    "# tensor([[1., 2., 5., 6.],  \n",
    "#         [3., 4., 7., 8.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stack\n",
    "- 지정된 모든 행렬을 dim 차원에 쌓아 새로운 차원을 만들고, \n",
    "- 차원이 하나 커진 행렬을 출력한다.\n",
    "- 이떄 지정된 dim 차원의 크기는 입력 행렬의 갯수임\n",
    "- 모든 입력 행렬들은 같은 크기를 가져야 한다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim=0 결과:\n",
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n",
      "shape: torch.Size([3, 4])\n",
      "\n",
      "dim=1 결과:\n",
      "tensor([[ 1,  5,  9],\n",
      "        [ 2,  6, 10],\n",
      "        [ 3,  7, 11],\n",
      "        [ 4,  8, 12]])\n",
      "shape: torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch  \n",
    "\n",
    "# 크기가 [4]인 1차원 텐서 생성  \n",
    "a = torch.tensor([1, 2, 3, 4])      # shape: [4]  \n",
    "b = torch.tensor([5, 6, 7, 8])      # shape: [4]  \n",
    "c = torch.tensor([9, 10, 11, 12])   # shape: [4]  \n",
    "\n",
    "# dim=0으로 stack (첫 번째 차원에 쌓기)  \n",
    "stacked = torch.stack([a, b, c], dim=0)  \n",
    "print(\"dim=0 결과:\")  \n",
    "print(stacked)  \n",
    "print(\"shape:\", stacked.shape)      # torch.Size([3, 4])  \n",
    "#                                     ↑   ↑  \n",
    "#                                     |   요소 개수 4개  \n",
    "#                                     텐서 3개 입력  \n",
    "\n",
    "# dim=1로 stack (두 번째 차원에 쌓기)  \n",
    "stacked_dim1 = torch.stack([a, b, c], dim=1)  \n",
    "print(\"\\ndim=1 결과:\")  \n",
    "print(stacked_dim1)  \n",
    "print(\"shape:\", stacked_dim1.shape)  # torch.Size([4, 3])  \n",
    "#                                      ↑   ↑  \n",
    "#                                      |   텐서 3개 입력  \n",
    "#                                      요소 개수 4개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ones and Zeros\n",
    "- 모든 요소가 0,1인 텐서 생성함\n",
    "- _like\n",
    "    - 입력 텐서와 동일한 크기의 모든 요소가 0,1 인 텐서 생성함\n",
    "- full\n",
    "    - 특정 값으로 채워진 텐서 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== 기본 초기화 함수 =====\n",
      "torch.zeros(2, 3):\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "데이터 타입: torch.float32\n",
      "\n",
      "torch.ones(2, 4):\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "\n",
      "정수형 zeros:\n",
      "tensor([[0, 0],\n",
      "        [0, 0]], dtype=torch.int32)\n",
      "데이터 타입: torch.int32\n",
      "\n",
      "===== _like 함수들 =====\n",
      "기준 텐서:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "크기: torch.Size([2, 3])\n",
      "\n",
      "torch.zeros_like(base_tensor):\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "\n",
      "torch.ones_like(base_tensor):\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]])\n",
      "\n",
      "실수형 ones_like:\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "데이터 타입: torch.float32\n",
      "\n",
      "===== 특정 값으로 채우기 =====\n",
      "torch.ones(2, 3) * 5:\n",
      "tensor([[5., 5., 5.],\n",
      "        [5., 5., 5.]])\n",
      "\n",
      "torch.full((2, 3), 7.5):\n",
      "tensor([[7.5000, 7.5000, 7.5000],\n",
      "        [7.5000, 7.5000, 7.5000]])\n",
      "\n",
      "torch.full_like(base_tensor, 9):\n",
      "tensor([[9, 9, 9],\n",
      "        [9, 9, 9]])\n"
     ]
    }
   ],
   "source": [
    "import torch  \n",
    "\n",
    "print(\"===== 기본 초기화 함수 =====\")  \n",
    "# torch.zeros()로 0으로 채운 텐서 생성  \n",
    "zeros_tensor = torch.zeros(2, 3)  \n",
    "print(\"torch.zeros(2, 3):\")  \n",
    "print(zeros_tensor)  \n",
    "print(\"데이터 타입:\", zeros_tensor.dtype)  \n",
    "\n",
    "# torch.ones()로 1로 채운 텐서 생성  \n",
    "ones_tensor = torch.ones(2, 4)  \n",
    "print(\"\\ntorch.ones(2, 4):\")  \n",
    "print(ones_tensor)  \n",
    "\n",
    "# 특정 데이터 타입 지정  \n",
    "int_zeros = torch.zeros(2, 2, dtype=torch.int32)  \n",
    "print(\"\\n정수형 zeros:\")  \n",
    "print(int_zeros)  \n",
    "print(\"데이터 타입:\", int_zeros.dtype)  \n",
    "\n",
    "print(\"\\n===== _like 함수들 =====\")  \n",
    "# 기준이 될 텐서 생성  \n",
    "base_tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])  \n",
    "print(\"기준 텐서:\")  \n",
    "print(base_tensor)  \n",
    "print(\"크기:\", base_tensor.shape)  \n",
    "\n",
    "# zeros_like  \n",
    "zeros_like_tensor = torch.zeros_like(base_tensor)  \n",
    "print(\"\\ntorch.zeros_like(base_tensor):\")  \n",
    "print(zeros_like_tensor)  \n",
    "\n",
    "# ones_like  \n",
    "ones_like_tensor = torch.ones_like(base_tensor)  \n",
    "print(\"\\ntorch.ones_like(base_tensor):\")  \n",
    "print(ones_like_tensor)  \n",
    "\n",
    "# 데이터 타입 변경  \n",
    "float_ones_like = torch.ones_like(base_tensor, dtype=torch.float)  \n",
    "print(\"\\n실수형 ones_like:\")  \n",
    "print(float_ones_like)  \n",
    "print(\"데이터 타입:\", float_ones_like.dtype)  \n",
    "\n",
    "print(\"\\n===== 특정 값으로 채우기 =====\")  \n",
    "# 특정 값으로 채우기 - 방법 1  \n",
    "fives = torch.ones(2, 3) * 5  \n",
    "print(\"torch.ones(2, 3) * 5:\")  \n",
    "print(fives)  \n",
    "\n",
    "# 특정 값으로 채우기 - 방법 2 (torch.full)  \n",
    "full_tensor = torch.full((2, 3), 7.5)  \n",
    "print(\"\\ntorch.full((2, 3), 7.5):\")  \n",
    "print(full_tensor)  \n",
    "\n",
    "# full_like  \n",
    "full_like_tensor = torch.full_like(base_tensor, 9)  \n",
    "print(\"\\ntorch.full_like(base_tensor, 9):\")  \n",
    "print(full_like_tensor)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-place Operation\n",
    "- 함수 맨 뒤에 _추가해 사용\n",
    "- 새 텐서를 반환하지 않고 기존 텐서의 메모리를 직접 수정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 x:\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "add_(5) 후:\n",
      "tensor([[6., 6., 6.],\n",
      "        [6., 6., 6.],\n",
      "        [6., 6., 6.]])\n",
      "\n",
      "mul_(2) 후:\n",
      "tensor([[12., 12., 12.],\n",
      "        [12., 12., 12.],\n",
      "        [12., 12., 12.]])\n",
      "\n",
      "zero_() 후:\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n",
      "fill_(7) 후:\n",
      "tensor([[7., 7., 7.],\n",
      "        [7., 7., 7.],\n",
      "        [7., 7., 7.]])\n",
      "\n",
      "copy_(y) 후:\n",
      "tensor([[ 0.8483,  0.7929, -1.0229],\n",
      "        [ 1.9905, -1.8861, -0.1985],\n",
      "        [-0.4668, -0.5371, -0.1189]])\n",
      "원본 y:\n",
      "tensor([[ 0.8483,  0.7929, -1.0229],\n",
      "        [ 1.9905, -1.8861, -0.1985],\n",
      "        [-0.4668, -0.5371, -0.1189]])\n"
     ]
    }
   ],
   "source": [
    "import torch  \n",
    "\n",
    "# 기본 텐서 생성  \n",
    "x = torch.ones(3, 3)  \n",
    "print(\"원본 x:\")  \n",
    "print(x)  \n",
    "\n",
    "# 1. add_: 덧셈 in-place 연산  \n",
    "x.add_(5)  # x = x + 5와 동일한 결과지만 새 메모리 할당 없음  \n",
    "print(\"\\nadd_(5) 후:\")  \n",
    "print(x)  \n",
    "\n",
    "# 2. mul_: 곱셈 in-place 연산  \n",
    "x.mul_(2)  # x = x * 2  \n",
    "print(\"\\nmul_(2) 후:\")  \n",
    "print(x)  \n",
    "\n",
    "# 3. zero_: 모든 원소를 0으로 초기화  \n",
    "x.zero_()  # x = torch.zeros_like(x)  \n",
    "print(\"\\nzero_() 후:\")  \n",
    "print(x)  \n",
    "\n",
    "# 4. fill_: 특정 값으로 채우기  \n",
    "x.fill_(7)  # x의 모든 원소를 7로 변경  \n",
    "print(\"\\nfill_(7) 후:\")  \n",
    "print(x)  \n",
    "\n",
    "# 5. copy_: 다른 텐서의 값 복사  \n",
    "y = torch.randn(3, 3)  \n",
    "x.copy_(y)  # y의 값을 x에 복사  \n",
    "print(\"\\ncopy_(y) 후:\")  \n",
    "print(x)  \n",
    "print(\"원본 y:\")  \n",
    "print(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
